{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Univariate model for conditional volatility\n",
    " - Base Model for comparing other models\n",
    " - 30 day rolling window estimate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn .preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "from numpy import split\n",
    "from numpy import array\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from matplotlib import pyplot\n",
    "from keras.layers import RepeatVector\n",
    "from keras.layers import TimeDistributed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "np.set_printoptions(suppress=True)\n",
    "import pandas as pd\n",
    "pd.options.display.float_format = '{:,.10f}'.format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data  = pd.read_excel('emotion.xls').drop('Date', axis=1 ).set_index(\"day\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Conditional Volatility</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>day</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2007-04-19</th>\n",
       "      <td>1.9240180000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-04-23</th>\n",
       "      <td>1.9290780000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-04-30</th>\n",
       "      <td>2.1650120000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-05-07</th>\n",
       "      <td>2.0097640000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-05-08</th>\n",
       "      <td>1.8497520000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Conditional Volatility\n",
       "day                               \n",
       "2007-04-19            1.9240180000\n",
       "2007-04-23            1.9290780000\n",
       "2007-04-30            2.1650120000\n",
       "2007-05-07            2.0097640000\n",
       "2007-05-08            1.8497520000"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data.iloc[:, -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 3168 entries, 2007-04-19 to 2020-03-16\n",
      "Data columns (total 1 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   Conditional Volatility  3168 non-null   float64\n",
      "dtypes: float64(1)\n",
      "memory usage: 49.5 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "train, test = df[18:3138], df[3138:3168]\n",
    "train = pd.DataFrame(scaler.fit_transform(train), columns=train.columns, index=train.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = array(split(train.values, len(train)/30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = array(split(test.values, len(test)/30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_supervised(train, n_input, n_out=30):\n",
    "\t# flatten data\n",
    "\tdata = train.reshape((train.shape[0]*train.shape[1], train.shape[2]))\n",
    "\tX, y = list(), list()\n",
    "\tin_start = 0\n",
    "\tfor _ in range(len(data)):\n",
    "\t\tin_end = in_start + n_input\n",
    "\t\tout_end = in_end + n_out\n",
    "\t\tif out_end <= len(data):\n",
    "\t\t\tX.append(data[in_start:in_end, :])\n",
    "\t\t\ty.append(data[in_end:out_end, 0])\n",
    "\t\tin_start += 1\n",
    "\treturn array(X), array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(train, n_input):\n",
    "\ttrain_x, train_y = to_supervised(train, n_input)\n",
    "\tverbose, epochs, batch_size = 1, 55, 20\n",
    "\tn_timesteps, n_features, n_outputs = train_x.shape[1], train_x.shape[2], train_y.shape[1]\n",
    "\t# reshape output into [samples, timesteps, features]\n",
    "\ttrain_y = train_y.reshape((train_y.shape[0], train_y.shape[1], 1))\n",
    "\tprint(train_x.shape)\n",
    "\tprint(train_y.shape)\n",
    "    \n",
    "\t# define model\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(LSTM(200, activation='relu', input_shape=(n_timesteps, n_features)))\n",
    "\tmodel.add(RepeatVector(n_outputs))\n",
    "\tmodel.add(LSTM(200, activation='relu', return_sequences=True))\n",
    "\tmodel.add(TimeDistributed(Dense(100, activation='relu')))\n",
    "\tmodel.add(TimeDistributed(Dense(1)))\n",
    "\tmodel.compile(loss='mse', optimizer='adam')\n",
    "\tmodel.summary()\n",
    "    \n",
    "\t# fit network\n",
    "\tmodel.fit(train_x, train_y, epochs=epochs, batch_size=batch_size, verbose=verbose)\n",
    "\treturn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3061, 30, 1)\n",
      "(3061, 30, 1)\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 200)               161600    \n",
      "_________________________________________________________________\n",
      "repeat_vector_1 (RepeatVecto (None, 30, 200)           0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 30, 200)           320800    \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 30, 100)           20100     \n",
      "_________________________________________________________________\n",
      "time_distributed_2 (TimeDist (None, 30, 1)             101       \n",
      "=================================================================\n",
      "Total params: 502,601\n",
      "Trainable params: 502,601\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/55\n",
      "3061/3061 [==============================] - 48s 16ms/step - loss: 0.0065\n",
      "Epoch 2/55\n",
      "3061/3061 [==============================] - 44s 14ms/step - loss: 0.0051\n",
      "Epoch 3/55\n",
      "3061/3061 [==============================] - 44s 14ms/step - loss: 0.0048\n",
      "Epoch 4/55\n",
      "3061/3061 [==============================] - 44s 14ms/step - loss: 0.0050\n",
      "Epoch 5/55\n",
      "3061/3061 [==============================] - 44s 14ms/step - loss: 0.0048\n",
      "Epoch 6/55\n",
      "3061/3061 [==============================] - 44s 14ms/step - loss: 0.0044\n",
      "Epoch 7/55\n",
      "3061/3061 [==============================] - 41s 13ms/step - loss: 0.0046\n",
      "Epoch 8/55\n",
      "3061/3061 [==============================] - 42s 14ms/step - loss: 0.0045\n",
      "Epoch 9/55\n",
      "3061/3061 [==============================] - 43s 14ms/step - loss: 0.0041\n",
      "Epoch 10/55\n",
      "3061/3061 [==============================] - 41s 13ms/step - loss: 0.0042\n",
      "Epoch 11/55\n",
      "3061/3061 [==============================] - 43s 14ms/step - loss: 0.0044\n",
      "Epoch 12/55\n",
      "3061/3061 [==============================] - 43s 14ms/step - loss: 0.0045\n",
      "Epoch 13/55\n",
      "3061/3061 [==============================] - 43s 14ms/step - loss: 0.0039\n",
      "Epoch 14/55\n",
      "3061/3061 [==============================] - 43s 14ms/step - loss: 0.0038\n",
      "Epoch 15/55\n",
      "3061/3061 [==============================] - 44s 14ms/step - loss: 0.0037\n",
      "Epoch 16/55\n",
      "3061/3061 [==============================] - 43s 14ms/step - loss: 0.0035\n",
      "Epoch 17/55\n",
      "3061/3061 [==============================] - 43s 14ms/step - loss: 0.0032\n",
      "Epoch 18/55\n",
      "3061/3061 [==============================] - 42s 14ms/step - loss: 0.0032\n",
      "Epoch 19/55\n",
      "3061/3061 [==============================] - 44s 14ms/step - loss: 0.0041\n",
      "Epoch 20/55\n",
      "3061/3061 [==============================] - 43s 14ms/step - loss: 0.0034\n",
      "Epoch 21/55\n",
      "3061/3061 [==============================] - 43s 14ms/step - loss: 0.0034\n",
      "Epoch 22/55\n",
      "3061/3061 [==============================] - 43s 14ms/step - loss: 0.0034\n",
      "Epoch 23/55\n",
      "3061/3061 [==============================] - 43s 14ms/step - loss: 0.0030\n",
      "Epoch 24/55\n",
      "3061/3061 [==============================] - 42s 14ms/step - loss: 0.0031\n",
      "Epoch 25/55\n",
      "3061/3061 [==============================] - 45s 15ms/step - loss: 0.0031\n",
      "Epoch 26/55\n",
      "3061/3061 [==============================] - 56s 18ms/step - loss: 0.0030\n",
      "Epoch 27/55\n",
      "3061/3061 [==============================] - 44s 14ms/step - loss: 0.0028\n",
      "Epoch 28/55\n",
      "3061/3061 [==============================] - 43s 14ms/step - loss: 0.0030\n",
      "Epoch 29/55\n",
      "3061/3061 [==============================] - 42s 14ms/step - loss: 0.0035\n",
      "Epoch 30/55\n",
      "3061/3061 [==============================] - 42s 14ms/step - loss: 0.0045\n",
      "Epoch 31/55\n",
      "3061/3061 [==============================] - 43s 14ms/step - loss: 0.0039\n",
      "Epoch 32/55\n",
      "3061/3061 [==============================] - 43s 14ms/step - loss: 0.0034\n",
      "Epoch 33/55\n",
      "3061/3061 [==============================] - 43s 14ms/step - loss: 0.0029\n",
      "Epoch 34/55\n",
      "3061/3061 [==============================] - 41s 13ms/step - loss: 0.0030\n",
      "Epoch 35/55\n",
      "3061/3061 [==============================] - 44s 14ms/step - loss: 0.0028\n",
      "Epoch 36/55\n",
      "3061/3061 [==============================] - 42s 14ms/step - loss: 0.0028\n",
      "Epoch 37/55\n",
      "3061/3061 [==============================] - 44s 14ms/step - loss: 0.0026\n",
      "Epoch 38/55\n",
      "3061/3061 [==============================] - 42s 14ms/step - loss: 0.0027\n",
      "Epoch 39/55\n",
      "3061/3061 [==============================] - 44s 14ms/step - loss: 0.0026\n",
      "Epoch 40/55\n",
      "3061/3061 [==============================] - 43s 14ms/step - loss: 0.0026\n",
      "Epoch 41/55\n",
      "3061/3061 [==============================] - 44s 14ms/step - loss: 0.0029\n",
      "Epoch 42/55\n",
      "3061/3061 [==============================] - 42s 14ms/step - loss: 0.0038\n",
      "Epoch 43/55\n",
      "3061/3061 [==============================] - 43s 14ms/step - loss: 0.0029\n",
      "Epoch 44/55\n",
      "3061/3061 [==============================] - 43s 14ms/step - loss: 0.0032\n",
      "Epoch 45/55\n",
      "3061/3061 [==============================] - 43s 14ms/step - loss: 0.0028\n",
      "Epoch 46/55\n",
      "3061/3061 [==============================] - 43s 14ms/step - loss: 0.0026\n",
      "Epoch 47/55\n",
      "3061/3061 [==============================] - 43s 14ms/step - loss: 0.0025\n",
      "Epoch 48/55\n",
      "3061/3061 [==============================] - 42s 14ms/step - loss: 0.0023\n",
      "Epoch 49/55\n",
      "3061/3061 [==============================] - 43s 14ms/step - loss: 0.0023\n",
      "Epoch 50/55\n",
      "3061/3061 [==============================] - 42s 14ms/step - loss: 0.0021\n",
      "Epoch 51/55\n",
      "3061/3061 [==============================] - 43s 14ms/step - loss: 0.0027\n",
      "Epoch 52/55\n",
      "3061/3061 [==============================] - 42s 14ms/step - loss: 0.0029\n",
      "Epoch 53/55\n",
      "3061/3061 [==============================] - 42s 14ms/step - loss: 0.0021\n",
      "Epoch 54/55\n",
      "3061/3061 [==============================] - 42s 14ms/step - loss: 0.0024\n",
      "Epoch 55/55\n",
      "3061/3061 [==============================] - 43s 14ms/step - loss: 0.0020\n",
      "model saved\n"
     ]
    }
   ],
   "source": [
    "n_input = 30 \n",
    "model = build_model(train, n_input) \n",
    "model.save( 'model7' + '.h5')\n",
    "print(\"model saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import loadtxt\n",
    "from keras.models import load_model  \n",
    "from keras.utils.vis_utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forecast(model, history, n_input):\n",
    "\t# flatten data\n",
    "\tdata = array(history)\n",
    "\tdata = data.reshape((data.shape[0]*data.shape[1], data.shape[2]))\n",
    "\t# retrieve last observations for input data\n",
    "\tinput_x = data[-n_input:, :]\n",
    "\t# reshape into [1, n_input, n]\n",
    "\tinput_x = input_x.reshape((1, input_x.shape[0], input_x.shape[1]))\n",
    "\t# forecast the next week\n",
    "\tyhat = model.predict(input_x, verbose=1)\n",
    "\t# we only want the vector forecast\n",
    "\tyhat = yhat[0]\n",
    "\treturn yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_forecasts_new(actual, predicted):\n",
    "\tscores = list()\n",
    "\t# calculate an RMSE score for each day\n",
    "\tfor i in range(actual.shape[1]):\n",
    "\t\tmse = mean_squared_error(actual[:, i], predicted[:, i])\n",
    "\t\trmse = sqrt(mse)\n",
    "\t\t# store\n",
    "\t\tscores.append(rmse)\n",
    "        \n",
    "\t# calculate overall RMSE\n",
    "\ts = 0\n",
    "\tfor row in range(actual.shape[0]):\n",
    "\t\tfor col in range(actual.shape[1]):\n",
    "\t\t\ts += (actual[row, col] - predicted[row, col])**2\n",
    "\tscore = sqrt(s / (actual.shape[0] * actual.shape[1]))\n",
    "\treturn score, scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_new(train, test, n_input):\n",
    "    \n",
    "\t# history is a list of weekly data\n",
    "\thistory = [x for x in train]\n",
    "    \n",
    "\t# walk-forward validation \n",
    "\tpredictions = list()\n",
    "    \n",
    "\tfor i in range(len(test)):\n",
    "\t\tyhat_sequence = forecast(model, history, n_input)\n",
    "# \t\tprint(type(yhat_sequence))\n",
    "# \t\tprint(yhat_sequence.shape) \n",
    "# \t\ty1 = scaler.inverse_transform(yhat_sequence)\n",
    "# \t\tprint(type(y1))\n",
    "# \t\tprint(y1.shape)    \n",
    "\t\tpredictions.append(yhat_sequence)\n",
    "\t\thistory.append(test[i, :])\n",
    "        \n",
    "\t# evaluate predictions days for each week\n",
    "\tpredictions = array(predictions)\n",
    "# \tprint(predictions.shape)  \n",
    "# \tpredictions = scaler.inverse_transform(predictions[0,:,:])\n",
    "\treturn predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 467ms/step\n"
     ]
    }
   ],
   "source": [
    "preds = evaluate_model_new(train, test, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds.shape\n",
    "predictions = scaler.inverse_transform(preds[0,:, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 30, 1)\n"
     ]
    }
   ],
   "source": [
    "predictions = predictions.reshape(1,-1,1)\n",
    "print(predictions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "score, scores = evaluate_forecasts_new(test[:, :, 0], predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_scores(name, score, scores):\n",
    "\ts_scores = ', '.join(['%.1f' % s for s in scores])\n",
    "\tprint('%s: [%.3f] %s' % (name, score, s_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test: [2.518] 0.1, 0.4, 0.3, 0.6, 0.5, 0.4, 0.3, 0.2, 0.2, 0.1, 0.1, 0.0, 0.0, 0.0, 0.0, 0.1, 0.2, 0.2, 0.2, 0.1, 1.2, 1.1, 1.0, 0.9, 0.8, 1.1, 3.4, 3.0, 8.8, 9.2\n"
     ]
    }
   ],
   "source": [
    "summarize_scores('test', score, scores)"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-gpu.2-1.m47",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-1:m47"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
